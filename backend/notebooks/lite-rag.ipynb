{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bbd9ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (4.1.0)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0-cp310-cp310-manylinux_2_28_x86_64.whl (31.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: Pillow in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: tqdm in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from sentence-transformers) (2.7.0)\n",
      "Requirement already satisfied: scipy in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\n",
      "Collecting numpy<3.0,>=1.25.0\n",
      "  Downloading numpy-2.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: filelock in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
      "Requirement already satisfied: networkx in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (2.8.8)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (0.6.3)\n",
      "Requirement already satisfied: jinja2 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (2.26.2)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (9.5.1.17)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from triton==3.3.0->torch>=1.11.0->sentence-transformers) (59.6.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mpmath<1.4,>=1.1.0 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.20)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/adharshrajendran/projects/resume-agent/backend/resume-agent/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Installing collected packages: numpy, faiss-cpu\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.22.0\n",
      "    Uninstalling numpy-1.22.0:\n",
      "      Successfully uninstalled numpy-1.22.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "melotts 0.1.2 requires transformers==4.27.4, but you have transformers 4.51.3 which is incompatible.\n",
      "faster-whisper 0.9.0 requires tokenizers<0.15,>=0.13, but you have tokenizers 0.21.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed faiss-cpu-1.11.0 numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f9dd8630",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = [\n",
    "  {\n",
    "    \"type\": \"project\",\n",
    "    \"title\": \"Visa HR and IT Agent Automation\",\n",
    "    \"content\": \"As an AI Technical Specialist at IBM in 2025, I led Visa HR and IT Agent projects that automated 80% of queries and reduced HR processing time from minutes to seconds. I integrated HR and IT systems using WatsonX Assistant, Orchestrate, ElasticSearch, OpenAPI, and ServiceNow API.\"\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"project\",\n",
    "    \"title\": \"FifthThirds Loan Processing Automation\",\n",
    "    \"content\": \"As an AI Engineer at IBM (2024–2025), I automated 75% of loan processing tasks and unified document analysis at FifthThirds Bank using Python Streamlit, Openshift, Kubernetes, and WatsonX Code Assistant. I also created prompts and chatbot flows for loan status inquiries and worked with COBOL systems for migration.\"\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"project\",\n",
    "    \"title\": \"Trellis WatsonX Enablement\",\n",
    "    \"content\": \"As an AI Engineer at IBM, I contributed to enabling WatsonX capabilities for Trellis, including prompt design, onboarding guidance, and integration with internal tools.\"\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"project\",\n",
    "    \"title\": \"Motorola Multi-Chatbot Platform\",\n",
    "    \"content\": \"As a Cloud & Systems Engineer at IBM (2021–2023), I helped close a $200,000 sale by delivering a multi-chatbot interface for Motorola, integrating multiple bots into a unified customer experience.\"\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"project\",\n",
    "    \"title\": \"Boeing Customer Care Assistant\",\n",
    "    \"content\": \"At IBM, I automated 70% of customer service queries and deployed 10+ projects via OpenShift for Boeing's customer care systems.\"\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"project\",\n",
    "    \"title\": \"Resume Agent\",\n",
    "    \"content\": \"I built Resume Agent, a voice-driven resume assistant using Flask, Whisper, and Ollama to deliver interactive resume generation.\"\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"project\",\n",
    "    \"title\": \"Tesla Tracker\",\n",
    "    \"content\": \"I developed Tesla Tracker, a home automation project using Raspberry Pi and Flask to track and log vehicle data from my Tesla.\"\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"project\",\n",
    "    \"title\": \"Real Estate Forecaster\",\n",
    "    \"content\": \"I created Real Estate Forecaster, a web app that visualizes housing market trends using Facebook Prophet.\"\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"tool\",\n",
    "    \"title\": \"Python\",\n",
    "    \"content\": \"Used for backend APIs, scripting, data pipelines, Streamlit dashboards, ML, and prompt orchestration.\"\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"tool\",\n",
    "    \"title\": \"Flask\",\n",
    "    \"content\": \"Used to build backend servers and audio pipelines for interactive web applications.\"\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"tool\",\n",
    "    \"title\": \"WatsonX Assistant\",\n",
    "    \"content\": \"Used to design, train, and deploy enterprise chat assistants for HR, finance, and support workflows.\"\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"tool\",\n",
    "    \"title\": \"Kubernetes & OpenShift\",\n",
    "    \"content\": \"Used to deploy scalable AI and chatbot solutions at IBM across multiple enterprise accounts.\"\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"tool\",\n",
    "    \"title\": \"ServiceNow API\",\n",
    "    \"content\": \"Used to automate support ticket workflows and integrate assistant responses with internal systems.\"\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"tool\",\n",
    "    \"title\": \"Streamlit\",\n",
    "    \"content\": \"Used for internal dashboarding tools and visual document triage apps.\"\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"tool\",\n",
    "    \"title\": \"ElasticSearch\",\n",
    "    \"content\": \"Used for session-based context retrieval and document grounding in assistants.\"\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"tool\",\n",
    "    \"title\": \"Docker\",\n",
    "    \"content\": \"Used to containerize assistant systems and internal app tooling.\"\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"tool\",\n",
    "    \"title\": \"Node.js & React\",\n",
    "    \"content\": \"Used to build frontend interfaces for assistant deployments and customer-facing apps.\"\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"tool\",\n",
    "    \"title\": \"PostgreSQL\",\n",
    "    \"content\": \"Used to persist user sessions, conversation logs, and assistant feedback metrics.\"\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"tool\",\n",
    "    \"title\": \"COBOL\",\n",
    "    \"content\": \"Worked with COBOL systems to migrate financial workflows into orchestrated AI experiences.\"\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d1d29ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d5a324c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1a6a8797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "384\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings))\n",
    "print(len(embeddings[0]))\n",
    "# Output: 5 for each chunk, respectively\n",
    "# Output: 384 values for each chunk, 384 dimensions\n",
    "# embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b5fe4d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "index = faiss.IndexFlatL2(384)  # 384 is the embedding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a53debf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(np.array(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ecd7f62f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<faiss.swigfaiss_avx2.IndexFlatL2; proxy of <Swig Object of type 'faiss::IndexFlatL2 *' at 0x74ed29927450> >"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f180ac39",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what have you worked on using Typescript?\"\n",
    "query_embedding = model.encode([query])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3855ce66",
   "metadata": {},
   "outputs": [],
   "source": [
    "D, I = index.search(np.array(query_embedding), k=2)  # Top 2 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0003e3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8 4]]\n",
      "[[1.4502182 1.5566792]]\n"
     ]
    }
   ],
   "source": [
    "print(I)\n",
    "# → array([[1, 0]])  # Top matching chunk indices\n",
    "print(D)\n",
    "# → array([[0.31, 0.42]])  # Smaller = more similar (L2 distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19e2bb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PROJECT: Resume Agent | TYPE: Voice-driven resume assistant | TOOLS: Flask, Whisper, Ollama\\nI built Resume Agent, a voice-driven resume assistant using Flask, Whisper, and Ollama to provide interactive resume generation.', 'TECHNOLOGY: COBOL | TASK: Migration and Integration\\nI also worked with COBOL systems as part of the migration and integration effort.']\n"
     ]
    }
   ],
   "source": [
    "results = [chunks[i] for i in I[0]]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26689864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed search, got results: [{'type': 'tool', 'title': 'Flask', 'content': 'Used to build backend servers and audio pipelines for interactive web applications.'}, {'type': 'tool', 'title': 'ServiceNow API', 'content': 'Used to automate support ticket workflows and integrate assistant responses with internal systems.'}, {'type': 'tool', 'title': 'WatsonX Assistant', 'content': 'Used to design, train, and deploy enterprise chat assistants for HR, finance, and support workflows.'}]\n",
      "Context for LLM: Tool: Flask\n",
      "Used to build backend servers and audio pipelines for interactive web applications.\n",
      "\n",
      "Tool: ServiceNow API\n",
      "Used to automate support ticket workflows and integrate assistant responses with internal systems.\n",
      "\n",
      "Tool: WatsonX Assistant\n",
      "Used to design, train, and deploy enterprise chat assistants for HR, finance, and support workflows.\n",
      "Full prompt: Based on the following background:\n",
      "        Tool: Flask\n",
      "Used to build backend servers and audio pipelines for interactive web applications.\n",
      "\n",
      "Tool: ServiceNow API\n",
      "Used to automate support ticket workflows and integrate assistant responses with internal systems.\n",
      "\n",
      "Tool: WatsonX Assistant\n",
      "Used to design, train, and deploy enterprise chat assistants for HR, finance, and support workflows.\n",
      "\n",
      "        what have you worked on using Typescript?\n",
      "Response:\n",
      " As Adharsh Rajendran, I've worked on several projects that utilize TypeScript in various capacities:\n",
      "\n",
      "1. **Backend Development with Flask**: In one project, I built a backend server for an interactive web application using Flask and TypeScript. The application required real-time audio processing, which was achieved by integrating WebRTC for peer-to-peer communication and Google's Web Speech API for speech recognition.\n",
      "\n",
      "2. **Integration with ServiceNow API**: I have worked on integrating a custom chatbot with the ServiceNow API to automate support ticket workflows. This involved writing TypeScript code to handle requests, parse responses, and manage the state of support tickets within our application.\n",
      "\n",
      "3. **WatsonX Assistant**: In another project, I designed, trained, and deployed an enterprise chat assistant for HR, finance, and support workflows using WatsonX (formerly IBM Watson Assistant\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "OLLAMA_URL = \"http://127.0.0.1:11434/api/generate\"  # Default Ollama endpoint\n",
    "MODEL_NAME = \"adharsh-mistral-normal\"  # Replace if you tagged your model differently (e.g., mistral-persona)\n",
    "\n",
    "def ask_llm(question):\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"prompt\": \"\",\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        query_embedding = model.encode([query]) # Get the embedding for the query\n",
    "        D, I = index.search(np.array(query_embedding), k=3)  # Top 3 results\n",
    "        results = [chunks[i] for i in I[0]]  # Get the top matching chunks\n",
    "        print(\"-------------------------------------\")\n",
    "        print(\"Completed search, got results:\", results)\n",
    "        print(\"-------------------------------------\")\n",
    "\n",
    "        context = \"\"\n",
    "        for i in results:\n",
    "            if i[\"type\"] == \"project\":\n",
    "                context += f\"Project: {i['title']}\\n{str(i['content'])}\\n\\n\"\n",
    "            elif i[\"type\"] == \"tool\":\n",
    "                context += f\"Tool: {i['title']}\\n{str(i['content'])}\\n\\n\"\n",
    "        context = context.strip()  # Clean up the context string\n",
    "        print(\"Context for LLM:\", context)\n",
    "        print(\"-------------------------------------\")\n",
    "\n",
    "        \n",
    "        full_prompt = f\"\"\"Based on the following background:\n",
    "        {context}\n",
    "\n",
    "        {question}\"\"\"\n",
    "\n",
    "        print(\"Full prompt:\", full_prompt)\n",
    "        print(\"-------------------------------------\")\n",
    "\n",
    "\n",
    "        payload[\"prompt\"] = full_prompt  # Add context to the prompt\n",
    "        response = requests.post(OLLAMA_URL, json=payload)\n",
    "        response.raise_for_status()\n",
    "        answer = response.json()[\"response\"]\n",
    "        return answer.strip()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Error communicating with Ollama:\", e)\n",
    "        return None\n",
    "\n",
    "# Example prompt\n",
    "question = \"what have you worked on using Typescript?\"\n",
    "response = ask_llm(question)\n",
    "print(\"Response:\\n\", response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resume-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
